@article{PURUSHOTHAM2018112,
    title = {Benchmarking deep learning models on large healthcare datasets},
    journal = {Journal of Biomedical Informatics},
    volume = {83},
    pages = {112-134},
    year = {2018},
    issn = {1532-0464},
    doi = {https://doi.org/10.1016/j.jbi.2018.04.007},
    url = {https://www.sciencedirect.com/science/article/pii/S1532046418300716},
    author = {Sanjay Purushotham and Chuizheng Meng and Zhengping Che and Yan Liu},
    keywords = {Deep learning models, Super learner algorithm, Mortality prediction, Length of stay, ICD-9 code group prediction},
    abstract = {Deep learning models (aka Deep Neural Networks) have revolutionized many fields including computer vision, natural language processing, speech recognition, and is being increasingly used in clinical healthcare applications. However, few works exist which have benchmarked the performance of the deep learning models with respect to the state-of-the-art machine learning models and prognostic scoring systems on publicly available healthcare datasets. In this paper, we present the benchmarking results for several clinical prediction tasks such as mortality prediction, length of stay prediction, and ICD-9 code group prediction using Deep Learning models, ensemble of machine learning models (Super Learner algorithm), SAPS II and SOFA scores. We used the Medical Information Mart for Intensive Care III (MIMIC-III) (v1.4) publicly available dataset, which includes all patients admitted to an ICU at the Beth Israel Deaconess Medical Center from 2001 to 2012, for the benchmarking tasks. Our results show that deep learning models consistently outperform all the other approaches especially when the ‘raw’ clinical time series data is used as input features to the models.}
}

@ARTICLE{650093,
    author={Schuster, M. and Paliwal, K.K.},
    journal={IEEE Transactions on Signal Processing}, 
    title={Bidirectional recurrent neural networks}, 
    year={1997},
    volume={45},
    number={11},
    pages={2673-2681},
    doi={10.1109/78.650093}
}

@misc{oxford,
    title={Oxford Languages},
    howpublished = {\url{https://languages.oup.com/google-dictionary-en/}}
}

@misc{ enwiki:1057905873,
    author = "{Wikipedia contributors}",
    title = "Time series --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2021",
    url = "https://en.wikipedia.org/w/index.php?title=Time_series&oldid=1057905873",
    note = "[Online; accessed 8-December-2021]"
}

@article{nademi,
author = {Nademi, Arash and Shafiei, Elham and Fakharian, Esmaeil and Kalvandi, Gholamreza and talaeezadeh, khalil},
year = {2019},
month = {08},
pages = {23-27},
title = {Predicting number of traumas using the seasonal time series model},
volume = {8},
doi = {10.4103/atr.atr_65_1}
}

@article {Juange018628,
	author = {Juang, Wang-Chuan and Huang, Sin-Jhih and Huang, Fong-Dee and Cheng, Pei-Wen and Wann, Shue-Ren},
	title = {Application of time series analysis in modelling and forecasting emergency department visits in a medical centre in Southern Taiwan},
	volume = {7},
	number = {11},
	elocation-id = {e018628},
	year = {2017},
	doi = {10.1136/bmjopen-2017-018628},
	publisher = {British Medical Journal Publishing Group},
	abstract = {Objective Emergency department (ED) overcrowding is acknowledged as an increasingly important issue worldwide. Hospital managers are increasingly paying attention to ED crowding in order to provide higher quality medical services to patients. One of the crucial elements for a good management strategy is demand forecasting. Our study sought to construct an adequate model and to forecast monthly ED visits.Methods We retrospectively gathered monthly ED visits from January 2009 to December 2016 to carry out a time series autoregressive integrated moving average (ARIMA) analysis. Initial development of the model was based on past ED visits from 2009 to 2016. A best-fit model was further employed to forecast the monthly data of ED visits for the next year (2016). Finally, we evaluated the predicted accuracy of the identified model with the mean absolute percentage error (MAPE). The software packages SAS/ETS V.9.4 and Office Excel 2016 were used for all statistical analyses.Results A series of statistical tests showed that six models, including ARIMA (0, 0, 1), ARIMA (1, 0, 0), ARIMA (1, 0, 1), ARIMA (2, 0, 1), ARIMA (3, 0, 1) and ARIMA (5, 0, 1), were candidate models. The model that gave the minimum Akaike information criterion and Schwartz Bayesian criterion and followed the assumptions of residual independence was selected as the adequate model. Finally, a suitable ARIMA (0, 0, 1) structure, yielding a MAPE of 8.91\%, was identified and obtained as Visitt=7111.161+(at+0.37462 at-1).Conclusion The ARIMA (0, 0, 1) model can be considered adequate for predicting future ED visits, and its forecast results can be used to aid decision-making processes.},
	issn = {2044-6055},
	URL = {https://bmjopen.bmj.com/content/7/11/e018628},
	eprint = {https://bmjopen.bmj.com/content/7/11/e018628.full.pdf},
	journal = {BMJ Open}
}

@article{kamath2018,
    author = {Kamath, Rajani and Kamat, Rajanish},
    year = {2018},
    month = {11},
    pages = {27-33},
    title = {Time-series Analysis and Forecasting of Rainfall at Idukki district, Kerala: Machine Learning Approach},
    volume = {11},
    journal = {Disaster Advances}
}
@misc{gamboa2017deep,
      title={Deep Learning for Time-Series Analysis}, 
      author={John Cristian Borges Gamboa},
      year={2017},
      eprint={1701.01887},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@book{brownlee2018,
  title     = "Deep Learning for Time Series Forecasting: Predict the Future with MLPs, CNNs and LSTMs in Python",
  author    = "Brownlee, Jason",
  year      = 2018,
}
@INPROCEEDINGS{7015739,
  author={Qiu, Xueheng and Zhang, Le and Ren, Ye and Suganthan, P. N. and Amaratunga, Gehan},
  booktitle={2014 IEEE Symposium on Computational Intelligence in Ensemble Learning (CIEL)}, 
  title={Ensemble deep learning for regression and time series forecasting}, 
  year={2014},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/CIEL.2014.7015739}
  }

@article{SEZER2020106181,
title = {Financial time series forecasting with deep learning : A systematic literature review: 2005–2019},
journal = {Applied Soft Computing},
volume = {90},
pages = {106181},
year = {2020},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2020.106181},
url = {https://www.sciencedirect.com/science/article/pii/S1568494620301216},
author = {Omer Berat Sezer and Mehmet Ugur Gudelek and Ahmet Murat Ozbayoglu},
keywords = {Deep learning, Finance, Computational intelligence, Machine learning, Time series forecasting, CNN, LSTM, RNN},
abstract = {Financial time series forecasting is undoubtedly the top choice of computational intelligence for finance researchers in both academia and the finance industry due to its broad implementation areas and substantial impact. Machine Learning (ML) researchers have created various models, and a vast number of studies have been published accordingly. As such, a significant number of surveys exist covering ML studies on financial time series forecasting. Lately, Deep Learning (DL) models have appeared within the field, with results that significantly outperform their traditional ML counterparts. Even though there is a growing interest in developing models for financial time series forecasting, there is a lack of review papers that solely focus on DL for finance. Hence, the motivation of this paper is to provide a comprehensive literature review of DL studies on financial time series forecasting implementation. We not only categorized the studies according to their intended forecasting implementation areas, such as index, forex, and commodity forecasting, but we also grouped them based on their DL model choices, such as Convolutional Neural Networks (CNNs), Deep Belief Networks (DBNs), and Long-Short Term Memory (LSTM). We also tried to envision the future of the field by highlighting its possible setbacks and opportunities for the benefit of interested researchers.}
}

@article{10.1093/bib/bbx044,
    author = {Miotto, Riccardo and Wang, Fei and Wang, Shuang and Jiang, Xiaoqian and Dudley, Joel T},
    title = "{Deep learning for healthcare: review, opportunities and challenges}",
    journal = {Briefings in Bioinformatics},
    volume = {19},
    number = {6},
    pages = {1236-1246},
    year = {2017},
    month = {05},
    abstract = "{Gaining knowledge and actionable insights from complex, high-dimensional and heterogeneous biomedical data remains a key challenge in transforming health care. Various types of data have been emerging in modern biomedical research, including electronic health records, imaging, -omics, sensor data and text, which are complex, heterogeneous, poorly annotated and generally unstructured. Traditional data mining and statistical learning approaches typically need to first perform feature engineering to obtain effective and more robust features from those data, and then build prediction or clustering models on top of them. There are lots of challenges on both steps in a scenario of complicated data and lacking of sufficient domain knowledge. The latest advances in deep learning technologies provide new effective paradigms to obtain end-to-end learning models from complex data. In this article, we review the recent literature on applying deep learning technologies to advance the health care domain. Based on the analyzed work, we suggest that deep learning approaches could be the vehicle for translating big biomedical data into improved human health. However, we also note limitations and needs for improved methods development and applications, especially in terms of ease-of-understanding for domain experts and citizen scientists. We discuss such challenges and suggest developing holistic and meaningful interpretable architectures to bridge deep learning models and human interpretability.}",
    issn = {1477-4054},
    doi = {10.1093/bib/bbx044},
    url = {https://doi.org/10.1093/bib/bbx044},
    eprint = {https://academic.oup.com/bib/article-pdf/19/6/1236/27119191/bbx044.pdf},
}

@ARTICLE{10.3389/fdata.2020.00004,
  
AUTHOR={Kaushik, Shruti and Choudhury, Abhinav and Sheron, Pankaj Kumar and Dasgupta, Nataraj and Natarajan, Sayee and Pickett, Larry A. and Dutt, Varun},   
	 
TITLE={AI in Healthcare: Time-Series Forecasting Using Statistical, Neural, and Ensemble Architectures},      
	
JOURNAL={Frontiers in Big Data},      
	
VOLUME={3},      

PAGES={4},     
	
YEAR={2020},      
	  
URL={https://www.frontiersin.org/article/10.3389/fdata.2020.00004},       
	
DOI={10.3389/fdata.2020.00004},      
	
ISSN={2624-909X},   
   
ABSTRACT={Both statistical and neural methods have been proposed in the literature to predict healthcare expenditures. However, less attention has been given to comparing predictions from both these methods as well as ensemble approaches in the healthcare domain. The primary objective of this paper was to evaluate different statistical, neural, and ensemble techniques in their ability to predict patients' weekly average expenditures on certain pain medications. Two statistical models, persistence (baseline) and autoregressive integrated moving average (ARIMA), a multilayer perceptron (MLP) model, a long short-term memory (LSTM) model, and an ensemble model combining predictions of the ARIMA, MLP, and LSTM models were calibrated to predict the expenditures on two different pain medications. In the MLP and LSTM models, we compared the influence of shuffling of training data and dropout of certain nodes in MLPs and nodes and recurrent connections in LSTMs in layers during training. Results revealed that the ensemble model outperformed the persistence, ARIMA, MLP, and LSTM models across both pain medications. In general, not shuffling the training data and adding the dropout helped the MLP models and shuffling the training data and not adding the dropout helped the LSTM models across both medications. We highlight the implications of using statistical, neural, and ensemble methods for time-series forecasting of outcomes in the healthcare domain.}
}

@article{navarro2020,
author = {Guillén-Navarro, Miguel and Martínez, Raquel and Llanes-Castro, Antonio and Bueno-Crespo, Andrés and Cecilia, José},
year = {2020},
month = {01},
pages = {1-14},
title = {A deep learning model to predict lower temperatures in agriculture},
volume = {12},
journal = {Journal of Ambient Intelligence and Smart Environments},
doi = {10.3233/AIS-200546}
}


@Article{s20051334,
AUTHOR = {Jin, Xue-Bo and Yang, Nian-Xiang and Wang, Xiao-Yi and Bai, Yu-Ting and Su, Ting-Li and Kong, Jian-Lei},
TITLE = {Hybrid Deep Learning Predictor for Smart Agriculture Sensing Based on Empirical Mode Decomposition and Gated Recurrent Unit Group Model},
JOURNAL = {Sensors},
VOLUME = {20},
YEAR = {2020},
NUMBER = {5},
ARTICLE-NUMBER = {1334},
URL = {https://www.mdpi.com/1424-8220/20/5/1334},
ISSN = {1424-8220},
ABSTRACT = {Smart agricultural sensing has enabled great advantages in practical applications recently, making it one of the most important and valuable systems. For outdoor plantation farms, the prediction of climate data, such as temperature, wind speed, and humidity, enables the planning and control of agricultural production to improve the yield and quality of crops. However, it is not easy to accurately predict climate trends because the sensing data are complex, nonlinear, and contain multiple components. This study proposes a hybrid deep learning predictor, in which an empirical mode decomposition (EMD) method is used to decompose the climate data into fixed component groups with different frequency characteristics, then a gated recurrent unit (GRU) network is trained for each group as the sub-predictor, and finally the results from the GRU are added to obtain the prediction result. Experiments based on climate data from an agricultural Internet of Things (IoT) system verify the development of the proposed model. The prediction results show that the proposed predictor can obtain more accurate predictions of temperature, wind speed, and humidity data to meet the needs of precision agricultural production.},
DOI = {10.3390/s20051334}
}

@INPROCEEDINGS{7415154,
  author={Salman, Afan Galih and Kanigoro, Bayu and Heryadi, Yaya},
  booktitle={2015 International Conference on Advanced Computer Science and Information Systems (ICACSIS)}, 
  title={Weather forecasting using deep learning techniques}, 
  year={2015},
  volume={},
  number={},
  pages={281-285},
  doi={10.1109/ICACSIS.2015.7415154}}

@INPROCEEDINGS{7280812,
  author={Hossain, Moinul and Rekabdar, Banafsheh and Louis, Sushil J. and Dascalu, Sergiu},
  booktitle={2015 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Forecasting the weather of Nevada: A deep learning approach}, 
  year={2015},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/IJCNN.2015.7280812}}

@INPROCEEDINGS{9531929,
  author={Atef, Mohammed and Khattab, Ahmed and Agamy, Essam A. and Khairy, Mohamed M.},
  booktitle={2021 IEEE International Midwest Symposium on Circuits and Systems (MWSCAS)}, 
  title={Deep Learning Based Time-Series Forecasting Framework for Olive Precision Farming}, 
  year={2021},
  volume={},
  number={},
  pages={1062-1065},
  doi={10.1109/MWSCAS47672.2021.9531929}}

@INPROCEEDINGS{8355458,
  author={Althelaya, Khaled A. and El-Alfy, El-Sayed M. and Mohammed, Salahadin},
  booktitle={2018 9th International Conference on Information and Communication Systems (ICICS)}, 
  title={Evaluation of bidirectional LSTM for short-and long-term stock market prediction}, 
  year={2018},
  volume={},
  number={},
  pages={151-156},
  doi={10.1109/IACS.2018.8355458}}

@article{SHEN2018895,
title = {Deep Learning with Gated Recurrent Unit Networks for Financial Sequence Predictions},
journal = {Procedia Computer Science},
volume = {131},
pages = {895-903},
year = {2018},
note = {Recent Advancement in Information and Communication Technology:},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.04.298},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918306781},
author = {Guizhu Shen and Qingping Tan and Haoyu Zhang and Ping Zeng and Jianjun Xu},
keywords = {Deep learning, GRU, SVM, financial time series, stock index},
abstract = {Gated recurrent unit (GRU) networks perform well in sequence learning tasks and overcome the problems of vanishing and explosion of gradients in traditional recurrent neural networks (RNNs) when learning long-term dependencies. Although they apply essentially to financial time series predictions, they are seldom used in the field. To fill this void, we propose GRU networks and its improved version for predicting trading signals for stock indexes of the Hang Seng Indexes (HSI), the Deutscher Aktienindex (DAX) and the S&P 500 Index from 1991 to 2017, and compare the GRU-based models with the traditional deep net and the benchmark classifier support vector machine (SVM). Experimental results show that the two GRU models proposed in this paper both obtain higher prediction accuracy on these data sets, and the improved version can effectively improve the learning ability of the model.}
}

@article{dutta2019,
author = {Dutta, Aniruddha and Kumar, Saket and Basu, Meheli},
year = {2019},
month = {01},
pages = {},
title = {A Gated Recurrent Unit Approach to Bitcoin Price Prediction},
journal = {SSRN Electronic Journal},
doi = {10.2139/ssrn.3514069}
}

@Article{a14080251,
AUTHOR = {Dey, Polash and Hossain, Emam and Hossain, Md. Ishtiaque and Chowdhury, Mohammed Armanuzzaman and Alam, Md. Shariful and Hossain, Mohammad Shahadat and Andersson, Karl},
TITLE = {Comparative Analysis of Recurrent Neural Networks in Stock Price Prediction for Different Frequency Domains},
JOURNAL = {Algorithms},
VOLUME = {14},
YEAR = {2021},
NUMBER = {8},
ARTICLE-NUMBER = {251},
URL = {https://www.mdpi.com/1999-4893/14/8/251},
ISSN = {1999-4893},
ABSTRACT = {Investors in the stock market have always been in search of novel and unique techniques so that they can successfully predict stock price movement and make a big profit. However, investors continue to look for improved and new techniques to beat the market instead of old and traditional ones. Therefore, researchers are continuously working to build novel techniques to supply the demand of investors. Different types of recurrent neural networks (RNN) are used in time series analyses, especially in stock price prediction. However, since not all stocks’ prices follow the same trend, a single model cannot be used to predict the movement of all types of stock’s price. Therefore, in this research we conducted a comparative analysis of three commonly used RNNs—simple RNN, Long Short Term Memory (LSTM), and Gated Recurrent Unit (GRU)—and analyzed their efficiency for stocks having different stock trends and various price ranges and for different time frequencies. We considered three companies’ datasets from 30 June 2000 to 21 July 2020. The stocks follow different trends of price movements, with price ranges of $30, $50, and $290 during this period. We also analyzed the performance for one-day, three-day, and five-day time intervals. We compared the performance of RNN, LSTM, and GRU in terms of R2 value, MAE, MAPE, and RMSE metrics. The results show that simple RNN is outperformed by LSTM and GRU because RNN is susceptible to vanishing gradient problems, while the other two models are not. Moreover, GRU produces lesser errors comparing to LSTM. It is also evident from the results that as the time intervals get smaller, the models produce lower errors and higher reliability.},
DOI = {10.3390/a14080251}
}

@book{zhou_rueckert_fichtinger_2020, place={London, United Kingdom}, title={Handbook of Medical Image Computing and computer assisted intervention}, publisher={Academic Press is an imprint of Elsevier}, author={Zhou, S. Kevin and Rueckert, Daniel and Fichtinger, Gabor}, year={2020}} 

@misc{li_johnson_yeung, title={Lecture 10: Recurrent neural networks}, url={http://cs231n.stanford.edu/slides/2018/cs231n_2018_lecture10.pdf}, journal={CS231n: Convolutional Neural Networks for Visual Recognition}, publisher={Stanford University}, author={Li, Fei-Fei and Johnson, Justin and Yeung, Serena}} 

@misc{soleimany, title={MIT Deep Learning 6.S191}, url={http://introtodeeplearning.com/2020/slides/6S191_MIT_DeepLearning_L2.pdf}, journal={6.S191 Introduction to Deep Learning}, author={Soleimany, Ava}} 

  @misc{ enwiki:1059073528,
    author = "{Wikipedia contributors}",
    title = "S&P 500 --- {Wikipedia}{,} The Free Encyclopedia",
    year = "2021",
    url = "https://en.wikipedia.org/w/index.php?title=S%26P_500&oldid=1059073528",
    note = "[Online; accessed 8-December-2021]"
  }

@misc{venkitesh_2021, title={Microsoft stock- time series analysis}, url={https://www.kaggle.com/vijayvvenkitesh/microsoft-stock-time-series-analysis}, journal={Kaggle}, author={Venkitesh, Vijay V}, year={2021}, month={Jun}} 

@misc{datopian, title={Standard and poor's (S\&P) 500 index data including dividend, earnings and P/E ratio}, url={https://datahub.io/core/s-and-p-500}, journal={DataHub}, author={Datopian}}

@misc{fred_2021, title={Crude oil prices: Brent - Europe}, url={https://fred.stlouisfed.org/series/DCOILBRENTEU}, journal={FRED}, year={2021}, month={Dec}} 

@misc{srk_2021, title={Cryptocurrency historical prices}, url={https://www.kaggle.com/sudalairajkumar/cryptocurrencypricehistory}, journal={Kaggle}, author={Srk}, year={2021}, month={Jul}} 
